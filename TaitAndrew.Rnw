\documentclass[10pt  ,usenames, dvipsnames]{article}
\usepackage{graphicx, verbatim}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{lipsum}
\usepackage{todonotes}
\usepackage[tableposition=top]{caption}
\usepackage{ifthen}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{listings}
\usepackage{color}
\setlength{\textwidth}{6.5in} 
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0in} 
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{-1.5cm}
\setlength{\parindent}{0cm}
\usepackage{setspace}
\usepackage{float}
\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{tabularx}
\usepackage{lmodern} % for bold teletype font
\usepackage{minted}
\usepackage{underscore}
\usepackage{pdfpages}
\usepackage{graphicx}

\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = red %Colour of citations
}

%\fancyhf{}
\rfoot{Andrew Tait \thepage}
\singlespacing
\usepackage[affil-it]{authblk} 
\usepackage{etoolbox}
\usepackage{lmodern}


% Notice the following package, it will help you cite papers
\usepackage[backend=bibtex ,sorting=none]{biblatex}
\bibliography{references}

\begin{filecontents*}{references.bib}

\end{filecontents*}


\begin{document}


\title{\LARGE Coursework  \\ Advanced Data Science (CMM536)}

\author{Andrew Tait, \textit{\href{1504693@rgu.ac.uk}{1504693@rgu.ac.uk}}}
\maketitle
% \begin{flushleft} \today \end{flushleft} 
\noindent\rule{16cm}{0.4pt}
%\underline{\hspace{3cm}
\ \\
%\thispagestyle{empty}

\section{Research}
The paper that was chosen for this work is \cite{PHRIDVIRAJ2014255}. The authors provided a full review on different streaming algorithms and method that handle data mining. Below is a review of this paper that includes problem statement, related work and methods applied.

\subsection{Problem Statement}
The process of data mining is to discover otherwise hidden information and patterns from already existing data. What makes this complicated when it comes to data streams is that unlike a traditional relation database or data warehouse there isn't a pre-defined structure. This paper outlines an algorithm that could possibly overcomes these difficulties.

\subsection{Relevant Work}
There is numerous related works and research in the field of data streaming. For instance the ACM KDDD international conference held in 2010, outlined the problem of finding the top-k frequent items in a data stream with flexible sliding widows. This would be only to mine the top-k frequent items, not reporting on all frequent items.

\subsection{Methods}
The paper outlines the issues that the new data streaming algorithm may face. This included memory constraint, data prepossessing choice of data structure, identifying data distributions and target concepts and dimensional reduction.
These are import issues to cover as they will reduce the efficiency and overall accuracy of the data streaming algorithm.

\subsection{Results}
The algorithm produces a decision tree which it outlines the nodes that are active/live as black, killed nodes as red and green nodes on the first level to indicate that they are not closed. It produces an more effective decision tree it only looks for the top-k frequent items in the decision and discards the rest.

\subsection{Conclusion}
As the subject matter is dealing with an unlimited amount of information, whether this will be from social media streams or general information retrieval. There is still problem to overcome with clustering, classification and topic detection in terms of data streaming. The proposed algorithm provides a starting point by creating a decision tree of the top-k frequent items.


\clearpage



\section {Data Streams}

\subsection{Dataset Choice}

The dataset that has been chosen for this part of the coursework is the 'adult' dataset. This is available on the UCI repository. It has been proved to a good evaluation of classification methods

\url{https://archive.ics.uci.edu/ml/datasets/adult}



\subsection{Data Exploration}

The main purpose of the adult dataset is to find out which characteristics of the us population affect if their income is either <=$50k or >=$50k



To start off I will clear the RStudio environment and import the required libraries.

<<eval=FALSE,comment=TRUE>>=
#Clean RStudio Environment
rm(list = ls())

#Import librarys
library(caret)
library(partykit)
library(mlbench)
library(RWeka)
library(C50)
library(datasets)
library(rpart)
library(ggplot2)
library(data.table)
library(stream)
library(mlbench)
library(doParallel)
library(streamMOA)
library(e1071)
library(RMOA)
library(ROCR)
library(tm)
library(wordcloud)
library(wordcloud,quietly=TRUE)
library(RColorBrewer,quietly=TRUE)

@

<<warning=FALSE,echo=FALSE, comment=FALSE, message=FALSE, Include=FALSE>>==

#Import librarys
library(caret)
library(partykit)
library(mlbench)
library(RWeka)
library(C50)
library(datasets)
library(rpart)
library(ggplot2)
library(data.table)
library(stream)
library(mlbench)
library(doParallel)
library(streamMOA)
library(e1071)
library(RMOA)
library(ROCR)
library(tm)
library(wordcloud)
library(wordcloud,quietly=TRUE)
library(RColorBrewer,quietly=TRUE)

@

Then set the working directory to the coursework folder

<<eval=FALSE,comment=TRUE>>=
#Set working directory
setwd("~/CMM536 Advanced Data Science/Coursework/CMM536_Coursework")
@

<<warning=FALSE,echo=FALSE, comment=FALSE, message=FALSE>>==
setwd("~/CMM536 Advanced Data Science/Coursework/CMM536_Coursework")
@

\clearpage

In order to the import the adult dataset, the feature names first need to be defined.
<<eval=FALSE,comment=TRUE>>=
#Feature names
adultNames <- c("age", "workclass", "fblwgt",
                "education", "education-num", 
                "martial-status",
                "occupation",
                "relationship",
                "race",
                "sex",
                "captial-gain",
                "captain-loss",
                "hours-per-week",
                "native-country",
                "class")
@

<<warning=FALSE,echo=FALSE>>==
#Feature names
adultNames <- c("age", "workclass", "fblwgt",
                "education", "education-num", 
                "martial-status",
                "occupation",
                "relationship",
                "race",
                "sex",
                "captial-gain",
                "captain-loss",
                "hours-per-week",
                "native-country",
                "class")
@

The adult dataset is then imported from adult.data file:
<<eval=FALSE,comment=TRUE>>=


#Import datasets
adult <- read.table("data/adult.data" ,header = FALSE, sep = ",",
                         strip.white = TRUE, col.names = adultNames,
                         na.strings = "?", stringsAsFactors = TRUE)
@


<<warning=FALSE,echo=FALSE>>==

#Import datasets
adult <- read.table("data/adult.data" ,header = FALSE, sep = ",",
                         strip.white = TRUE, col.names = adultNames,
                         na.strings = "?", stringsAsFactors = TRUE)
@

Now the adult dataset is imported, it's time for some basic exploration

Number of rows (instances) in the dataset

<<eval=FALSE,comment=TRUE>>=
nrow(adult)
@

<<warning=FALSE,echo=FALSE>>==
nrow(adult)
@

The number of columns (features)

<<eval=FALSE,comment=TRUE>>=
ncol(adult)
@

<<warning=FALSE,echo=FALSE>>==
ncol(adult)
@

Summary of the adult dataset:

<<eval=FALSE,comment=TRUE>>=
#inspect dataset
str(adult)
@

<<warning=FALSE,echo=FALSE>>==
str(adult)
@



Now that some basic data exploration is covered, next to inspect the dataset a bit further. Starting with the class distribution in the adult dataset, see (Figure~\ref{fig1})

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Class Distribution
barplot(table(adult$class))
@

\begin{figure}[H]
\begin{center}
<<warning=FALSE,echo=FALSE,fig.height=8.5,out.width=".76\\linewidth">>=
#Class Distribution
barplot(table(adult$class))
@
\caption {Barplot of Class Distribution}
\label{fig1}
\end {center}
\end {figure}

As the barplot clearly shows, the adult dataset is highly unbalanced with <=50k being the majority class by a large margin!

\clearpage

\subsection{Build Classifier}

\subsubsection{Pre-Processing}
Before the adult dataset can classified, some pre-processing is required first.

The dataset is checked for missing values ('?')
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Check for missing values ('?')
table(complete.cases (adult))
@

<<warning=FALSE,echo=FALSE>>==
table(complete.cases (adult))
@

As shown above there are missing values in the workclass,occupation and class columns. so these are removed.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
cleanadult = adult[!is.na(adult$workclass)& !is.na(adult$occupation) & !is.na(adult$class),]
@


<<warning=FALSE,echo=FALSE>>==
cleanadult = adult[!is.na(adult$workclass)& !is.na(adult$occupation) & !is.na(adult$class),]
@

The flwgt feature is also removed as it's not required.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Remove flwgt feature
cleanadult$fblwgt = NULL
@

<<warning=FALSE,echo=FALSE>>==
#Remove flwgt feature
cleanadult$fblwgt = NULL
@

Lets inspect the cleanadult dataframe before going further:

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
str(cleanadult)
@

<<warning=FALSE,echo=FALSE>>==
str(cleanadult)
@


\clearpage

As the adult dataset is a mixture of factors, integers and characters, I decided that transforming the dataset into binary. This will be create features based on every possible value in the dataset.

The cleanadult dataframe is first copied and the class is removed (it's not being transformed into binary)

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Copy dataset
noClass <-cleanadult
#Remove class as it is not being transformed to binary
noClass$class <- NULL
@


<<warning=FALSE,echo=FALSE>>==
#Copy dataset
noClass <-cleanadult
#Remove class as it is not being transformed to binary
noClass$class <- NULL
@

Then the noClass dataframe is transformed into binary

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
binaryVars <- caret::dummyVars(~ ., data = noClass)
newAdult <- predict(binaryVars, newdata = noClass)
@

<<warning=FALSE,echo=FALSE>>==
binaryVars <- caret::dummyVars(~ ., data = noClass)
newAdult <- predict(binaryVars, newdata = noClass)
@

The class feature is then added to the binarised dataset
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#add class to binarised dataset
binAdult <-cbind(newAdult, cleanadult[14])
@

<<warning=FALSE,echo=FALSE>>==
binAdult <-cbind(newAdult, cleanadult[14])
@

Any rows with NA values after being binary transformed.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#remove any rows with NA values
row.has.na <- apply(binAdult, 1, function(x){any(is.na(x))})
sum(row.has.na)
binAdult <- binAdult[!row.has.na,]
@

Number of NA rows removed.
<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#remove any rows with NA values
row.has.na <- apply(binAdult, 1, function(x){any(is.na(x))})
sum(row.has.na)
binAdult <- binAdult[!row.has.na,]
@

\clearpage

\subsubsection{Classification}

When it came to dividing the mushroom dataset into training and testing subsets, I decided to go with 80
percent training and 20 percent testing split as a starting point/baseline. 
Since the class distribution is unbalanced, I thought this split would cover the majority of cases.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#split 80% training and 20% testing datasets
inTrain <- createDataPartition(y=binAdult$class, p=0.8, list=FALSE)

#Assign indexes to split the binAdult dataset into training and testing
training <- binAdult[inTrain,]
testing <- binAdult[inTrain,]
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#split 80% training and 20% testing datasets
inTrain <- createDataPartition(y=binAdult$class, p=0.8, list=FALSE)

#Assign indexes to split the binAdult dataset into training and testing
training <- binAdult[inTrain,]
testing <- binAdult[inTrain,]
@


For the initial classifier I decided to go with the kNN Classifier as it has proven to be a good baseline in previous labs and exercises in R.
Before the classification begins, parallel processing is enabled to speed up this process.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Setup Parallel processing to speed up classification modelling
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)
@

<<warning=FALSE,echo=FALSE>>==
#Setup Parallel processing to speed up classification modelling
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)
@

The train control is set to repeated-cross-validation with 10 folds and 3 repeats
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 3,
                     number = 10,
                     verboseIter=TRUE)
@


<<warning=FALSE,echo=FALSE>>==
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 3,
                     number = 10,
                     verboseIter=TRUE)
@
Next the seed is set to 1, in order to make the model reproducible and the kNN model is set up with the train control from above and k value set to 3.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
# ensure reproducibility of results by setting the seed to a known value
set.seed(1)
#use knn
mod21.knn<- train(class~., data=training, 
                  method="knn", tuneGrid=expand.grid(.k=3),trControl=ctrl)
@

<<warning=FALSE,echo=FALSE, message=FALSE, cache=TRUE>>==
set.seed(1)
#use knn
mod21.knn<- train(class~., data=training, 
                  method="knn", tuneGrid=expand.grid(.k=3),trControl=ctrl)
@


\clearpage

Once the knn Model is complete, it’s time to analyse the results, first with a print of the kNNModel as shown below.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
print(mod21.knn)
@

<<warning=FALSE,echo=FALSE>>==
print(mod21.knn)
@

On first inspection, the knnModel produces an accuracy of 83.61\% and kappa value of 0.55. Further evaluation can be found in the next section.

\clearpage

\subsubsection {Evaluation}

To evaluate the module, a confusion matrix is produced by predicting the against the testing (20 percent of the total dataset ) subset.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Evaluation
predictkNN <- predict(mod21.knn,testing)
confusionMatrix(predictkNN, testing$class)
@


<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#Evaluation
predictkNN <- predict(mod21.knn,testing)
confusionMatrix(predictkNN, testing$class)
@

As the confusion matrix shows that the kNNmodel produced an accuracy of 89.33\% when predicted against the training subset.

It correctly classified 17026 rows as <=50k and 4530 rows as >=50k.
However 1098 rows were incorrectly classified as <=50k and 1477 rows were incorrectly classified as >50k.

Overall it's a good start and could be improved upon further, with more computing resources and time to hand.

\clearpage

\subsection{Build Stream Classifier}

For the data streaming classifier, I used the binary adult dataset as used in the kNN model.

First the binary adult dataset is copied to a dataframe.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Pre-processing
#copy the binary adult dataset
df <- binAdult
@

<<warning=FALSE,echo=FALSE>>==
df <- binAdult
@

Next the control settings for the classification model are configured.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
ctrl <- MOAoptions(model = "OCBoost", randomSeed = 123456789, ensembleSize = 25,
                   smoothingParameter = 0.5)
mymodel <- OCBoost(control = ctrl)
mymodel
@


<<warning=FALSE,echo=FALSE>>==
ctrl <- MOAoptions(model = "OCBoost", randomSeed = 123456789, ensembleSize = 25,
                   smoothingParameter = 0.5)
mymodel <- OCBoost(control = ctrl)
mymodel
@

After setting the classification model, it's time to create the data stream and set some variables to control the iteration over the stream (see for loop)

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Create datastream from the dataframe.
dfStream <-datastream_dataframe(data=as.data.table(df))
#Set variables for stream iteration
chunk <- 100
turns <- (nrow(dfStream$data)/chunk)-1
turns <- floor(turns)
position <- chunk
@

<<warning=FALSE,echo=FALSE>>==
#Create datastream from the dataframe.
dfStream <-datastream_dataframe(data=as.data.table(df))
#Set variables for stream iteration
chunk <- 100
turns <- (nrow(dfStream$data)/chunk)-1
turns <- floor(turns)
position <- chunk
@

Next a sample of the dataset is created (first 100 rows)

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#first sample (train)
sample <- dfStream$get_points(dfStream, n =chunk,
                             outofpoints = c("stop", "warn", "ignore"))
@

<<warning=FALSE,echo=FALSE>>==
#first sample (train)
sample <- dfStream$get_points(dfStream, n =chunk,
                             outofpoints = c("stop", "warn", "ignore"))
@


For verification that the sample and original rows are the same, the first 10 classes of each are displayed. Note there are 105 features from the binary dataset, so displaying them all will take up a lot of pages, so only the class is shown for simplicity.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
head(sample$class,10)
head(df$class,10)
@

The first 10 classes of the sample chunk
<<warning=FALSE,echo=FALSE>>==
head(sample$class,10)
@

The first 10 classes of the df dataframe.
<<warning=FALSE,echo=FALSE>>==
head(sample$class,10)
@

With all the streaming data now setup, the model can be trained using the 1st chunk of data and then iterated against the whole of the data stream.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
##Train the first chunk

myboostedclasifier <- trainMOA(model=mymodel,
                      formula = class~.,
                      data = datastream_dataframe(sample))

#Now iterate ove the whole stream
for (i in 1:turns){
  #next sample 
  
  sample <- dfStream$get_points(dfStream, n =chunk,
                                outofpoints = c("stop", "warn", "ignore"))
  
  #update the trained model with the new chunks
  myboostedclasifier <- trainMOA(model = myboostedclasifier$model,
                        formula = class~., 
                        data = datastream_dataframe(sample),
                        reset = FALSE, trace=FALSE)
  
  cat("chunk: ",i, "\n")
}
@


<<warning=FALSE,echo=FALSE, cache=TRUE>>==
##Train the first chunk
myboostedclasifier <- trainMOA(model=mymodel,
                      formula = class~.,
                      data = datastream_dataframe(sample))

#Now iterate ove the whole stream
for (i in 1:turns){
  #next sample 
  
  sample <- dfStream$get_points(dfStream, n =chunk,
                                outofpoints = c("stop", "warn", "ignore"))
  
  #update the trained model with the new chunks
  myboostedclasifier <- trainMOA(model = myboostedclasifier$model,
                        formula = class~., 
                        data = datastream_dataframe(sample),
                        reset = FALSE, trace=FALSE)
  
}
@

Now that first sample has been tested, lets make some predictions

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
##Do some prediction to test the model

predictions <- predict(myboostedclasifier, sample)
table(sprintf("Reality: %s", sample$class),
      sprintf("Predicted: %s", predictions))


predictions <- as.factor(predictions)
confusion.mstream <- confusionMatrix(predictions, sample$class)

cat("Accuracy is: ", confusion.mstream$overall["Accuracy"])
@

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
Accuracy is:  0.86
@


With a sample of the data stream tested, lets do the same with the whole stream.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Hold results in a vector
accuracies <- c()
dfStream$reset()

for(i in 1:turns){
  #next sample
  
  sample <- dfStream$get_points(dfStream, n=chunk,
                                outofpoints = c("Stop", "warn", "ignore"))
  predictions <- predict(myboostedclasifier, sample)
  #Convert predictions to a factor so it will work with confusion matrix
  predictions <- as.factor(predictions)
  
  #caculate accuracy
  confusion.mstream <- confusionMatrix(predictions, sample$class)
  accuracies[i] <- confusion.mstream$overall["Accuracy"]
  
  cat(accuracies[i],"%","\n")
  
}
@


<<warning=FALSE,echo=FALSE, cache=TRUE, Message=FALSE>>==
#Hold results in a vector
accuracies <- c()
dfStream$reset()

for(i in 1:turns){
  #next sample
  
  sample <- dfStream$get_points(dfStream, n=chunk,
                                outofpoints = c("Stop", "warn", "ignore"))
  predictions <- predict(myboostedclasifier, sample)
  #Convert predictions to a factor so it will work with confusion matrix
  predictions <- as.factor(predictions)
  
  #caculate accuracy
  confusion.mstream <- confusionMatrix(predictions, sample$class)
  accuracies[i] <- confusion.mstream$overall["Accuracy"]
  
}
@

Check the head of the accuracies 

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
head(accuracies)

@
<<warning=FALSE,echo=FALSE>>==
head(accuracies)

@

Finally lets plot the accuracy vs the chunk number

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
plot(accuracies,type='l',col='red',
     xlab="Chunk Number",ylab="Accuracy",frame=FALSE)
@


\begin{figure}[H]
\begin{center}
<<warning=FALSE,echo=FALSE>>==
plot(accuracies,type='l',col='red',
     xlab="Chunk Number",ylab="Accuracy",frame=FALSE)
@
\caption {Chunk Number vs Accuracy}
\label{fig2}
\end {center}
\end {figure}

As the plot above shows, the overall accuracy varies as the chunk number increases. Although it drops to bellow 70\% just after 50 chunks and again just before 150 chunks. The highest accuracy value is between 170 and 190 chunks.

The limitation for data streaming is that the adult dataset is unbalanced, also to improve classification models more computing resources would be required. As this is a length process that is restricted to the computing power provided on my laptop.

\clearpage

\section {Text Classification}
For this task a csv of leave/remain tweets of the brexit campaign was provided.

The was first imported:
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
leaveRemainTweets <- read.csv("data/leaveRemainTweets_CW.csv", header=TRUE)
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
leaveRemainTweets <- read.csv("data/leaveRemainTweets_CW.csv", header=TRUE)
@

Then the tweets are split based on the label(leave/remain)

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#split dataset into leave and remain dataframes
tweets = split(leaveRemainTweets, leaveRemainTweets$label)
remainTweets = tweets$Remain
leaveTweets = tweets$Leave
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#split dataset into leave and remain dataframes
tweets = split(leaveRemainTweets, leaveRemainTweets$label)
remainTweets = tweets$Remain
leaveTweets = tweets$Leave
@

Next lets check how many leave/remain tweets they are
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
nrow(remainTweets)
nrow(leaveTweets)
@

Number of remain tweets
<<warning=FALSE,echo=FALSE>>==
nrow(remainTweets)
@

Number of leave tweets
<<warning=FALSE,echo=FALSE>>==
nrow(leaveTweets)
@


\subsection{Preprocessing}

In order to pre-process the leaveRemain tweets, I built a custom corpus function. Which can be found below.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
buildCorpus <- function (tweets, wordCloud, wholeDataSet, wordAssocation, dtm){
  
  #Check the optional parameters are set
  wordA <-hasArg(wordAssocation)
  wds <- hasArg(wholeDataSet)
  wordc <-  hasArg(wordCloud)
  dtmcheck <- hasArg(dtm)
  
  corp <- Corpus(VectorSource(tweets$text))
  
  
  corp <- tm_map(corp,
                 content_transformer(function(x) iconv(x, to='ASCII',
                                                       sub='byte')))
  # remove stop words and other preprocessing
  
  corp <- tm_map(corp, content_transformer(tolower))
  corp <- tm_map(corp, removeNumbers)
  
  toSpace = content_transformer( function(x, pattern) gsub(pattern," ",x) )
  
  
  ##Tweet cleaning
  
  #credit to https://stackoverflow.com/a/31352005/8816204
  corp <-tm_map(corp, toSpace, "(RT|via)((?:\\b\\W*@\\w+)+)")
  corp <-tm_map(corp, toSpace, "@\\w+")
  corp <-tm_map(corp, toSpace, "&amp")
  
  ##Remove URLS from tweets
  corp <-tm_map(corp, toSpace, "httpsw+")
  corp <-tm_map(corp, toSpace, "http:\\w+")
  corp <-tm_map(corp, toSpace, "https:\\w+")
  
  corp <-tm_map(corp, toSpace, "[ \t]{2,}")
  corp <-tm_map(corp, toSpace, "^\\s+|\\s+$")
  
  
  # ##Remove obvious words /stopwords
  if(wds){
    if(wholeDataSet){
      corp <- tm_map(corp, function(x)removeWords
                     (x,c(stopwords("english"),"amp", "will", "‰Û_", "https", "http", "httpsdb"    
                          , "eu", "brexit", "rt", "leave", "remain", "vote")))
    }
  } 
  else{
    corp <- tm_map(corp, function(x)removeWords
                   (x,c(stopwords("english"),"amp", "will", "‰Û_", "https", "http", "httpsdb")))  
  }
  
  
  
  #remove punctuation last so urls are removed correctly
  corp <- tm_map(corp, removePunctuation)
  

  #If wordAssocation is true then create term document  matrix
  if(wordA){
    if(wordAssocation){
      tdm <- TermDocumentMatrix(corp)
    }
    else{
      if(dtm){  # if dtm is true the create document term matrix
        dtm <- DocumentTermMatrix(corp)
      }
    }
    
  }
 
  else if(!wordA){ # If no  wordAssocation then create TermDocument Matrix
    tdm <- TermDocumentMatrix(corp)
    
    m <- as.matrix(tdm)
    v <- sort(rowSums(m), decreasing = TRUE)
    d <- data.frame(word = names(v), freq = v)
    d$word <- gsub("˜", " ", d$word) ## Edit 2
    
    
    if(wordc){
      if(wds){
        tweets <- d$word #whole dataset return df of processed tweets
      } else{
        tweets <- d$word
        if(wordCloud){ #return wordcloud if TRUE
          wordcloud(words =tweets, freq = d$freq, min.freq = 3,
                    max.words=2000, random.order=FALSE, rot.per=0.2,
                    colors=brewer.pal(8, "Dark2"))
        }
      }
      
    }
    
  }
 
}
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#Custom Corpus Function for preprocessing  

buildCorpus <- function (tweets, wordCloud, wholeDataSet, wordAssocation, dtm){
  
  #Check the optional parameters are set
  wordA <-hasArg(wordAssocation)
  wds <- hasArg(wholeDataSet)
  wordc <-  hasArg(wordCloud)
  dtmcheck <- hasArg(dtm)
  
  corp <- Corpus(VectorSource(tweets$text))
  
  
  corp <- tm_map(corp,
                 content_transformer(function(x) iconv(x, to='ASCII',
                                                       sub='byte')))
  # remove stop words and other preprocessing
  
  corp <- tm_map(corp, content_transformer(tolower))
  corp <- tm_map(corp, removeNumbers)
  
  toSpace = content_transformer( function(x, pattern) gsub(pattern," ",x) )
  
  
  ##Tweet cleaning
  
  #credit to https://stackoverflow.com/a/31352005/8816204
  corp <-tm_map(corp, toSpace, "(RT|via)((?:\\b\\W*@\\w+)+)")
  corp <-tm_map(corp, toSpace, "@\\w+")
  corp <-tm_map(corp, toSpace, "&amp")
  
  ##Remove URLS from tweets
  corp <-tm_map(corp, toSpace, "httpsw+")
  corp <-tm_map(corp, toSpace, "http:\\w+")
  corp <-tm_map(corp, toSpace, "https:\\w+")
  
  corp <-tm_map(corp, toSpace, "[ \t]{2,}")
  corp <-tm_map(corp, toSpace, "^\\s+|\\s+$")
  
  
  # ##Remove obvious words /stopwords
  if(wds){
    if(wholeDataSet){
      corp <- tm_map(corp, function(x)removeWords(x,c(stopwords("english"),"amp", "will", "‰Û_", "https", "http", "httpsdb", "eu", "brexit", "rt", "leave", "remain", "vote")))
    }
  } else{
    corp <- tm_map(corp, function(x)removeWords(x,c(stopwords("english"),"amp", "will", "‰Û_", "https", "http", "httpsdb")))  
  }
  
  
  
  #remove punctuation last so urls are removed correctly
  corp <- tm_map(corp, removePunctuation)
  
  #If wordAssocation is true then 
  

  
  #If wordAssocation is true then create term document  matrix
  if(wordA){
    if(wordAssocation){
      tdm <- TermDocumentMatrix(corp)
    }
    else{
      if(dtm){
        dtm <- DocumentTermMatrix(corp)
      }
    }
    
  }
 
  else if(!wordA){ # If no  wordAssocation then create TermDocument Matrix
    tdm <- TermDocumentMatrix(corp)
    
    m <- as.matrix(tdm)
    v <- sort(rowSums(m), decreasing = TRUE)
    d <- data.frame(word = names(v), freq = v)
    d$word <- gsub("˜", " ", d$word) ## Edit 2
    
    
    if(wordc){
      if(wds){
        tweets <- d$word
      } else{
        tweets <- d$word
        if(wordCloud){
          wordcloud(words =tweets, freq = d$freq, min.freq = 3,
                    max.words=2000, random.order=FALSE, rot.per=0.2,
                    colors=brewer.pal(8, "Dark2"))
        }
      }
      
    }
    
  }
 
}
@

By using the buildCorpus function with the word cloud parameter set to TRUE, it will create a word cloud for us. 
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
leaveWordCloud <- buildCorpus(leaveTweets,TRUE)

remainWordCloud <- buildCorpus(remainTweets,TRUE)
@

Please see (Figure~\ref{fig3}) for leave tweets word cloud and (Figure~\ref{fig4}) for remain tweets wordcloud.

\begin{figure}[H]
\begin{center}
<<warning=FALSE,echo=FALSE,cache=TRUE,fig.height=6.0,out.width=".80\\linewidth">>=
leaveWordCloud <- buildCorpus(leaveTweets,TRUE)
@
\caption {Word cloud of leave tweets}
\label{fig3}
\end {center}
\end {figure}


\begin{figure}[H]
\begin{center}
<<warning=FALSE,echo=FALSE,cache=TRUE,fig.height=6.0,out.width=".80\\linewidth">>=
remainWordCloud <- buildCorpus(remainTweets,TRUE)
@
\caption {Word cloud of Remain tweets}
\label{fig4}
\end {center}
\end {figure}


\clearpage


\subsection{Text Analysis}

\subsubsection{Most Frequent word in Tweet Collection}

To find the most frequent word in the collection of tweets, the whole leaveRemainTweets dataframe was based into the buildCorpus function with the wordCloud option set to FALSE and wholedataset option set to TRUE.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Get Most frequent word
tweetWordCloud <-buildCorpus(leaveRemainTweets, FALSE, TRUE)
head(tweetWordCloud,1)
@


<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#Get Most frequent word
tweetWordCloud <-buildCorpus(leaveRemainTweets, FALSE, TRUE)
head(tweetWordCloud,1)
@


\subsubsection{Word Association}


To find out which words appear together often, I used the buildCorpus function to return a termDocumentMatrix. The most frequent terms with a lowfreq value of 50 is also created.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
wordAssoication <- buildCorpus(leaveRemainTweets,FALSE,TRUE,TRUE)
freq.terms <- findFreqTerms(wordAssoication, lowfreq =50)
@


<<warning=FALSE,echo=FALSE, cache=TRUE>>==
wordAssoication <- buildCorpus(leaveRemainTweets,FALSE,TRUE,TRUE)
freq.terms <- findFreqTerms(wordAssoication, lowfreq =50)
@


Lets inspect the top 30 most frequent words in the tweet collection


<<warning=FALSE,eval=FALSE,comment=TRUE>>==
head(freq.terms,30)
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
head(freq.terms,30)
@

Now to plot (Figure~\ref{fig5}) the word association (term document matrix) against the frequent terms.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
plot(wordAssoication, term = freq.terms, corThreshold = 0.12, weighting = T)
@

In the plot, the thicker the line between words the greater the association. In this case June as a strong association with imagine and vote leave.

Similar with European with 'must' and 'now'. Also 'Farage' and 'debate'.

\begin{figure}[H]
\begin{center}
\includegraphics[page=1,width=.90\textwidth]{{wordAPlot.pdf}}
\caption {Word Association Plot (Zoom to see words)}
\label{fig5}
\end {center}
\end {figure}



% \includepdf[pages={1-},scale=0.75]{wordAPlot.pdf}




\subsubsection{Most Frequent Words in Both Leave \& Remain Tweets}

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Leave
leaveWords <- buildCorpus(leaveTweets, FALSE,TRUE)
head(leaveWords, 10)
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#Leave
leaveWords <- buildCorpus(leaveTweets, FALSE,TRUE)
head(leaveWords, 10)
@


<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Remain
remainWords <- buildCorpus(remainTweets, FALSE,TRUE)
head(remainWords, 10)
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#Remain
remainWords <- buildCorpus(remainTweets, FALSE,TRUE)
head(remainWords, 10)
@

\clearpage

\subsection{Text Classification}

\subsubsection{kNNModel}
For the text classification of the brexit tweets, I decided to use the kNN Model again, as it has proven to be good starting/base line in previous exercises.


First off I used my buildCorpus function again but set the wholedataset parameter to TRUE, along with the dtm parameter to TRUE.

This creates a document term matrix, that is changed to a matrix and dataframe in turn.
The tweet label is added to the new dataframe.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Create a document term matrix from build corpus function.
dtm <-  buildCorpus(leaveRemainTweets,FALSE,TRUE,FALSE,TRUE)

#Convert dtm to matrix
dtm <- as.matrix(dtm)
#Then a data frame
tweets <- data.frame(dtm)
#Add label to dataframe
tweets$label <- leaveRemainTweets$label
@


<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#Get term document matrix
dtm <-  buildCorpus(leaveRemainTweets,FALSE,TRUE,FALSE,TRUE)

dtm <- as.matrix(dtm)
tweets <- data.frame(dtm)

tweets$label <- leaveRemainTweets$label
@

The tweets are then separated into 70\% training and 30\% testing subsets (prevent over fitting from occurring).

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Split data into training and testing subsets
#Divide the dataset into 70% training and 30% testing, to prevent overfitting from occurring
inTrainTweets <- createDataPartition(y=tweets$label, p=0.7, list=FALSE)

#Assign indexes to split the Tweets DTM into training and testing
training <- tweets[inTrainTweets,]
testing <- tweets[-inTrainTweets,]
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#Split data into training and testing subsets
#Divide the dataset into 70% training and 30% testing, to prevent overfitting from occurring
inTrainTweets <- createDataPartition(y=tweets$label, p=0.7, list=FALSE)

#Assign indexes to split the Tweets DTM into training and testing
training <- tweets[inTrainTweets,]
testing <- tweets[-inTrainTweets,]
@

The kNN Model is then setup with cross validation (5 fold) and a tune length of 5. 

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
train_control<- trainControl(method="cv", number=5,verboseIter=FALSE)

kNNTweets <- train(label~., data = training,
                  trControl = train_control,
                  tuneLength =5,
                  method = "knn"
          
)
@


<<warning=FALSE,echo=FALSE, cache=TRUE>>==
train_control<- trainControl(method="cv", number=5,verboseIter=FALSE)

kNNTweets <- train(label~., data = training,
                  trControl = train_control,
                  tuneLength =5,
                  method = "knn"
          
)
@


<<warning=FALSE,eval=FALSE,comment=TRUE>>==
kNNTweets
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
kNNTweets
@

At first inspect of the kNN Model it produces an accuracy of 84.80\% and a kappa value of 68.48\%


<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Evaluate

predictkNNTweets <- predict(kNNTweets,testing)
confusionMatrix(predictkNNTweets, testing$label)
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
predictkNNTweets <- predict(kNNTweets,testing)
confusionMatrix(predictkNNTweets, testing$label)
@

When predicted against the testing subset the kNNModel, it produces an accuracy of 83.63\%, which isn't too bad but not excellent either. As it incorrectly classifies 108 leave tweets and 4 remain tweets incorrectly.


\clearpage

\subsubsection{Improved SVM Model}

To improve the classification model, I decided to use the supported vector machine algorithm.

The parameters are the same as the knnModel to make a fairer comparison.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==


#Set Train Control to cross-validation 5 fold
train_control<- trainControl(method="cv", number=5,verboseIter=FALSE)

#Set model to SVM with tunelength of 10

svmModel <- train(label~ ., data = training,
                  trControl = train_control,
                  tuneLength =10,
                  method = "svmRadial"
                
)
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
#Turn on Parraell Processing to speed up classification
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)

#Set Train Control to cross-validation 5 fold
train_control<- trainControl(method="cv", number=5,verboseIter=FALSE)

#Set model to SVM with tunelength of 10

svmModel <- train(label~ ., data = training,
                  trControl = train_control,
                  tuneLength =10,
                  method = "svmRadial"
                
)
@

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
svmModel
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
svmModel
@

The highest accuracy the SVM model produces is 90.49\% at the c value of 4.


\clearpage

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Evaluate

predictSVM <- predict(svmModel,testing)
confusionMatrix(predictSVM, testing$label)
@

<<warning=FALSE,echo=FALSE, cache=TRUE>>==
predictSVM <- predict(svmModel,testing)
confusionMatrix(predictSVM, testing$label)
@

When compared against the testing subset, the Accuracy is 92.69\% , which is a nearly 10\% performance increased against the kNNModel. With only 20 leave tweets and 30 remain tweets incorrectly classified.

\clearpage



% Clear the page and starte a new page for references 

\clearpage
% The title for the reference section is called References 

\section{References}\label{pubs}

\printbibliography[heading =none]


\clearpage


\end{document}
